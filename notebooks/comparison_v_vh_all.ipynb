{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook generates statistics for IWP retrievals(test data), Used for Fig. 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from iwc2tb.GMI.gmiData_test import gmiData\n",
    "import os\n",
    "from iwc2tb.GMI.three_sigma_rule import three_sigma\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.03, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.17, 0.19, 0.21,\n",
       "       0.23, 0.25, 0.27, 0.29, 0.31, 0.33, 0.35, 0.37, 0.39, 0.41, 0.43,\n",
       "       0.45, 0.47, 0.49, 0.51, 0.53, 0.55, 0.57, 0.59, 0.61, 0.63, 0.65,\n",
       "       0.67, 0.69, 0.71, 0.73, 0.75, 0.77, 0.79, 0.81, 0.83, 0.85, 0.87,\n",
       "       0.89, 0.91, 0.93, 0.95, 0.97, 0.99])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.linspace(0.01, 0.99, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles         = np.linspace(0.01, 0.99, 50)\n",
    "imedian            = np.argwhere((quantiles >= 0.49) & (quantiles < 0.51))[0][0]\n",
    "alist      = [\"0\", \"1\", \"2\", \"3\" ] \n",
    "alist      = [\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AY      = []\n",
    "AY_pre  = []\n",
    "AY_mean = []\n",
    "PR      = []\n",
    "for i in alist:\n",
    "    \n",
    "    filename_aro = \"qrnn_gmi_nn_lpa_v\" + i + \"_jan.pickle\"\n",
    "\n",
    "    with open(filename_aro, \"rb\") as f:   \n",
    "        ay      = pickle.load(f)\n",
    "        ay_pre  = pickle.load(f)\n",
    "        ay_mean = pickle.load(f)\n",
    "        pr      = pickle.load(f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "    AY.append(ay)\n",
    "    AY_pre.append(ay_pre.reshape(-1, 1, 50))\n",
    "    AY_mean.append(ay_mean.reshape(-1, 1))\n",
    "    PR.append(pr)\n",
    "\n",
    "AY      = np.concatenate(AY, axis = 1)\n",
    "AY_pre  = np.concatenate(AY_pre, axis = 1)\n",
    "AY_mean = np.concatenate(AY_mean, axis = 1)\n",
    "PR      = np.concatenate(PR, axis = 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY      = []\n",
    "TY_pre  = []\n",
    "TY_mean = []\n",
    "\n",
    "for i in alist:\n",
    "    \n",
    "    filename_aro = \"qrnn_gmi_nn_lpa_pr1_v\" + i + \"_jan.pickle\" \n",
    "\n",
    "    with open(filename_aro, \"rb\") as f:   \n",
    "        ty      = pickle.load(f)\n",
    "        ty_pre  = pickle.load(f)\n",
    "        ty_mean = pickle.load(f)\n",
    "        pr      = pickle.load(f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "    TY.append(ty)\n",
    "    TY_pre.append(ty_pre.reshape(-1, 1, 50))\n",
    "    TY_mean.append(ty_mean.reshape(-1, 1))\n",
    "\n",
    "\n",
    "TY      = np.concatenate(TY, axis = 1)\n",
    "TY_pre  = np.concatenate(TY_pre, axis = 1)\n",
    "TY_mean = np.concatenate(TY_mean, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1681625, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AY_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold(AY, AY_mean):\n",
    "    AY[AY < 1e-4] = 1e-4\n",
    "    AY_mean[AY_mean < 1e-4] = 1e-4\n",
    "    return AY, AY_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AV      = []\n",
    "AV_pre  = []\n",
    "AV_mean = []\n",
    "\n",
    "for i in alist:\n",
    "    \n",
    "    filename_aro = \"qrnn_gmi_nn_lpa_v\" + i + \"_jan_v.pickle\" \n",
    "\n",
    "    with open(filename_aro, \"rb\") as f:   \n",
    "        ty      = pickle.load(f)\n",
    "        ty_pre  = pickle.load(f)\n",
    "        ty_mean = pickle.load(f)\n",
    "        pr      = pickle.load(f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "    AV.append(ty)\n",
    "    AV_pre.append(ty_pre.reshape(-1, 1, 50))\n",
    "    AV_mean.append(ty_mean.reshape(-1, 1))\n",
    "\n",
    "\n",
    "AV      = np.concatenate(AV, axis = 1)\n",
    "AV_pre  = np.concatenate(AV_pre, axis = 1)\n",
    "AV_mean = np.concatenate(AV_mean, axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TV      = []\n",
    "TV_pre  = []\n",
    "TV_mean = []\n",
    "\n",
    "for i in alist:\n",
    "    \n",
    "    filename_aro = \"qrnn_gmi_nn_lpa_pr1_v\" + i + \"_jan_v.pickle\"\n",
    "\n",
    "    with open(filename_aro, \"rb\") as f:   \n",
    "        ty      = pickle.load(f)\n",
    "        ty_pre  = pickle.load(f)\n",
    "        ty_mean = pickle.load(f)\n",
    "        pr      = pickle.load(f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "    TV.append(ty)\n",
    "    TV_pre.append(ty_pre.reshape(-1, 1, 50))\n",
    "    TV_mean.append(ty_mean.reshape(-1, 1))\n",
    "\n",
    "\n",
    "TV      = np.concatenate(TV, axis = 1)\n",
    "TV_pre  = np.concatenate(TV_pre, axis = 1)\n",
    "TV_mean = np.concatenate(TV_mean, axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AY, AY_mean = below_threshold(AY, AY_mean)\n",
    "TY, TY_mean = below_threshold(TY, TY_mean)\n",
    "\n",
    "AV, AV_mean = below_threshold(AV, AV_mean)\n",
    "TV, TV_mean = below_threshold(TV, TV_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (269.10440480280033, 20.6436588064602), 1: (265.58086973735675, 23.676729564773165), 2: (266.1501373130499, 14.274910875833077), 3: (257.7065563232903, 10.021202788202373), 4: (286.61770363132, 14.281002757198248), 5: (23.0027955926007, 16.823302635276093), 6: (169.73314260732718, 512.1075619128192), 7: (-1.5001814941685525, 37.62187709361819)}\n"
     ]
    }
   ],
   "source": [
    "batchSize          = 256\n",
    "inputs             = np.array( [\"ta\", \"t2m\",  \"wvp\", \"z0\", \"lat\",  \"stype\"])\n",
    "outputs            = \"iwp\"\n",
    "xlog               = True\n",
    "latlims            = [0, 65]\n",
    "test_data          = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_val_jan2010_withnoise.nc\"), \n",
    "                             inputs,\n",
    "                             outputs,\n",
    "                             batch_size = batchSize,\n",
    "                             latlims = latlims,\n",
    "                             normalise = None,)\n",
    "                             #log_iwp = xlog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = test_data.lat\n",
    "lat = np.repeat(lat, AY.shape[1], axis = 1)\n",
    "tb  = test_data.x[:, :4]\n",
    "TB = np.repeat(tb.reshape(-1, 4, 1), AY.shape[1], axis = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(amask, figname = \"scatter_tb.png\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize = [15, 6])\n",
    "    ax = ax.ravel()\n",
    "    ax[0].scatter(AY, AY_mean, color = \"tab:blue\", label = \"all\")\n",
    "    cs = ax[1].scatter(TY, TY_mean, color = \"tab:blue\", label = \"all\")\n",
    "\n",
    "    x = np.arange(0.0001, 15, 1)\n",
    "    y = x\n",
    "\n",
    "    ax[1].scatter(TY[amask], TY_mean[amask], color = \"tab:red\", alpha = 0.2, label = \"subset\")\n",
    "    ax[0].scatter(AY[amask], AY_mean[amask], color = \"tab:red\", alpha = 0.2, label = \"subset\")\n",
    "    ax[0].plot(x, y, \"k\")\n",
    "    ax[1].plot(x, y, \"k\")\n",
    "    ax[0].set_title(\"ARO based training\")\n",
    "    ax[1].set_title(\"TRO based training\")\n",
    "    ax[0].set_xlabel(r\"IWP0 [kg m$^{-2}$]\")\n",
    "    ax[0].set_ylabel(r\"IWP_mean [kg m$^{-2}$]\")\n",
    "\n",
    "    ax[1].set_xlabel(r\"IWP0 [kg m$^{-2}$]\")\n",
    "    ax[1].set_ylabel(r\"IWP_mean [kg m$^{-2}$]\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[0].set_xlim([0, 20])\n",
    "    ax[1].set_xlim([0, 20])\n",
    "    ax[0].set_ylim([0, 20])\n",
    "    ax[1].set_ylim([0, 20])\n",
    "\n",
    "    #ax[1].set_yscale(\"log\")\n",
    "    #ax[1].set_xscale(\"log\")\n",
    "    #ax[0].set_yscale(\"log\")\n",
    "    #ax[0].set_xscale(\"log\")\n",
    "    fig.savefig(figname, bbox_inches = \"tight\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stype = test_data.stype\n",
    "stype = np.argmax(stype, axis = 1)\n",
    "stype = np.squeeze(stype)\n",
    "stype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stype = np.repeat(stype.reshape(-1, 1), AY.shape[1], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_mask(lsmmask, figname):\n",
    "    fig, ax = plt.subplots(1, 2, figsize = [15, 6])\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    x = np.arange(0.0001, 15, 1)\n",
    "    y = x\n",
    "\n",
    "    ax[1].scatter(ty[lsmmask], ty_mean[lsmmask], c = pr[lsmmask],\n",
    "                  vmin = 1.2, vmax = 1.4, alpha = 0.5, label = \"subset\", cmap = cm.Blues)\n",
    "    cs = ax[0].scatter(ay[lsmmask], ay_mean[lsmmask], c = pr[lsmmask], \n",
    "                       vmin = 1.2, vmax = 1.4, alpha = 0.5, label = \"subset\", cmap = cm.Blues)\n",
    "    fig.colorbar(cs, ax = ax)\n",
    "    ax[0].plot(x, y, \"k\")\n",
    "    ax[1].plot(x, y, \"k\")\n",
    "    ax[0].set_title(\"ARO based training\")\n",
    "    ax[1].set_title(\"TRO based training\")\n",
    "    ax[0].set_xlabel(r\"IWP0 [kg m$^{-2}$]\")\n",
    "    ax[0].set_ylabel(r\"IWP_mean [kg m$^{-2}$]\")\n",
    "\n",
    "    ax[1].set_xlabel(r\"IWP0 [kg m$^{-2}$]\")\n",
    "    ax[1].set_ylabel(r\"IWP_mean [kg m$^{-2}$]\")\n",
    "    #ax[0].legend()\n",
    "    #ax[1].legend()\n",
    "    ax[0].set_xlim([1e-4, 20])\n",
    "    ax[1].set_xlim([1e-4, 20])\n",
    "    ax[0].set_ylim([1e-4, 20])\n",
    "    ax[1].set_ylim([1e-4, 20])\n",
    "\n",
    "    #ax[1].set_yscale(\"log\")\n",
    "    #ax[1].set_xscale(\"log\")\n",
    "    #ax[0].set_yscale(\"log\")\n",
    "    #ax[0].set_xscale(\"log\")\n",
    "    fig.savefig(figname, bbox_inches = \"tight\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(y, y0):\n",
    "    return np.mean(y-y0)\n",
    "\n",
    "def mae(y, y0):\n",
    "    return np.mean(np.abs(y-y0))\n",
    "\n",
    "def rmsd(y, y0):\n",
    "    return np.sqrt(np.mean((y-y0)**2))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(y, y0):\n",
    "    \n",
    "    bias = np.mean(y-y0)\n",
    "    mae  = np.mean(np.abs(y-y0))\n",
    "    rms  = np.sqrt(np.mean((y-y0)**2))\n",
    "    std  = np.std(y - y0)\n",
    "    mean = np.mean(y)\n",
    "    \n",
    "    return bias, mae, std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_dataframe(Y_mean, Y, PR, stype, TB):\n",
    "    statistics_aro = np.zeros([8, 4])\n",
    "\n",
    "    # all data\n",
    "    statistics_aro[0, :] = stats(Y_mean, Y)\n",
    "    \n",
    "    # water\n",
    "    amask = (stype == 0)\n",
    "    statistics_aro[1, :] = stats(Y_mean[amask], Y[amask])\n",
    "\n",
    "    # land\n",
    "    amask = (stype == 1) \n",
    "    statistics_aro[2, :] = stats(Y_mean[amask], Y[amask])\n",
    "\n",
    "    # snow \n",
    "    amask = (stype == 2) \n",
    "    statistics_aro[3, :] = stats(Y_mean[amask], Y[amask])\n",
    "\n",
    "    # seaice\n",
    "    amask = (stype == 3) \n",
    "    statistics_aro[4, :] = stats(Y_mean[amask], Y[amask])\n",
    "    \n",
    "    # coastlines\n",
    "    amask = (stype == 4) \n",
    "    statistics_aro[5, :] = stats(Y_mean[amask], Y[amask])\n",
    "\n",
    "    # snow+land boundary\n",
    "    amask = (stype == 7)\n",
    "    statistics_aro[6, :] = stats(Y_mean[amask], Y[amask])\n",
    "\n",
    "    # water+seaice boundary \n",
    "    amask = (stype == 6) \n",
    "    statistics_aro[7, :] = stats(Y_mean[amask], Y[amask])\n",
    "\n",
    "\n",
    "\n",
    "    statistics_aro = np.round(statistics_aro, decimals = 3)\n",
    "    \n",
    "    DF_aro = pd.DataFrame(statistics_aro, columns = [\"Bias\", \"MAE\", \"RMSD\", \"Mean\"], \n",
    "                  index = [\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land boundary\",\n",
    "                           \"seaice/water boundary\"])\n",
    "    \n",
    "    return DF_aro, statistics_aro\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_AY, _ = stats_dataframe(AY_mean, AY, PR, stype, TB[:, 0, :])\n",
    "DF_TY, _ = stats_dataframe(TY_mean, TY, PR, stype, TB[:, 0, :])\n",
    "\n",
    "DF_AV, _ = stats_dataframe(AV_mean, AV, PR, stype, TB[:, 0, :])\n",
    "DF_TV, _ = stats_dataframe(TV_mean, TV, PR, stype, TB[:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1681625, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e9eb1bd3da79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mTB_bs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mstats_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAY_mean_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAY_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPR_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTB_bs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mstats_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTY_mean_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTY_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPR_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTB_bs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 2."
     ]
    }
   ],
   "source": [
    "# bootstrap\n",
    "stats_a = np.zeros([500, 8, 4])\n",
    "stats_t = np.zeros([500, 8, 4])\n",
    "for j in range(500):\n",
    "    iargs = np.random.randint(0, AY_mean.size, int(AY_mean.size*0.1))\n",
    "    AY_mean_bs = AY_mean[iargs, 0]\n",
    "    TY_mean_bs = TY_mean[iargs, 0]\n",
    "    AY_bs = AY[iargs, 0]\n",
    "    TY_bs = TY[iargs, 0]\n",
    "    PR_bs = PR[iargs, 0]\n",
    "    stype_bs = stype[iargs, 0]\n",
    "    TB_bs = TB[iargs, 0, 0]\n",
    "\n",
    "    stats_a[j, :, :] = stats_dataframe(AY_mean_bs, AY_bs, PR_bs, stype_bs, TB_bs)\n",
    "    stats_t[j, :, :] = stats_dataframe(TY_mean_bs, TY_bs, PR_bs, stype_bs, TB_bs)\n",
    "\n",
    "std_a = np.std(stats_a, axis = 0)\n",
    "std_t = np.std(stats_t, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = (lat >-65.) & (lat <= -45.) \n",
    "#im = np.abs(lat) <=30.0\n",
    "#im = np.abs(lat) > 45.0\n",
    "#im = (np.abs(lat) > 30.0) & (np.abs(lat) < 45.0)\n",
    "#im = lat > 45\n",
    "#im = (lat > 30) & (lat <= 45)\n",
    "DF_AY_tr = stats_dataframe(AY_mean[im], AY[im], PR[im], stype[im], TB[:, 0, :][im])\n",
    "DF_TY_tr = stats_dataframe(TY_mean[im], TY[im], PR[im], stype[im], TB[:, 0, :][im])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_AY_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_TY_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_AY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_TY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.44 - 0.37)/0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwpmask = (AY > 0.01) & (AY < 0.5)\n",
    "DF_AY_1 = stats_dataframe(AY_mean[iwpmask], AY[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_TY_1 = stats_dataframe(TY_mean[iwpmask], TY[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_AV_1 = stats_dataframe(AV_mean[iwpmask], AV[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_TV_1 = stats_dataframe(TV_mean[iwpmask], TV[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwpmask = AY > 0.5\n",
    "DF_AY_2 = stats_dataframe(AY_mean[iwpmask], AY[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_TY_2 = stats_dataframe(TY_mean[iwpmask], TY[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_AV_2 = stats_dataframe(AV_mean[iwpmask], AV[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_TV_2 = stats_dataframe(TV_mean[iwpmask], TV[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwpmask = AY < 0.01\n",
    "DF_AY_3 = stats_dataframe(AY_mean[iwpmask], AY[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_TY_3 = stats_dataframe(TY_mean[iwpmask], TY[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_AV_3 = stats_dataframe(AV_mean[iwpmask], AV[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])\n",
    "DF_TV_3 = stats_dataframe(TV_mean[iwpmask], TV[iwpmask], PR[iwpmask], stype[iwpmask], TB[:, 0, :][iwpmask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(1, 9, 1)\n",
    "fig, ax = plt.subplots(2, 1, figsize = [16, 8])\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, var in enumerate([\"Bias\", \"MAE\"]):\n",
    "    ax[i].bar(xx - 0.25, DF_AY[var], width = 0.20, color = \"tab:blue\", alpha = 0.8, label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx - 0.125, DF_TY[var], width = 0.20, color = \"tab:blue\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx + 0.125, DF_AV[var], width = 0.20, color = \"tab:orange\", alpha = 0.8, label = \"LPA-ARO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_TV[var], width = 0.20, color = \"tab:orange\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO (V)\")\n",
    "    ax[1].plot(xx, DF_AY[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[0].set_xticklabels([])\n",
    "    ax[1].set_xticklabels([\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land \\n boundary\",\n",
    "                           \"seaice/water \\n boundary\"], rotation = 0, wrap = True)\n",
    "    ax[i].tick_params(axis='x', labelsize=20)\n",
    "ax[1].legend(bbox_to_anchor=(1., 1.45), frameon = False)\n",
    "\n",
    "xx == np.arange(-1, 11, 1)\n",
    "yy = np.zeros([xx.size])\n",
    "ax[0].plot(xx, yy, 'k')\n",
    "#ax[1].set_ylim([0, 0.1])\n",
    "#fig.suptitle(\"All data\")\n",
    "fig.savefig(\"ARO_TRO_v_vh.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(1, 9, 1)\n",
    "fig, ax = plt.subplots(2, 1, figsize = [16, 8])\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, var in enumerate([\"Bias\", \"MAE\"]):\n",
    "    ax[i].bar(xx - 0.25, DF_AY_1[var], width = 0.20, color = \"tab:blue\", alpha = 0.8, label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx - 0.125, DF_TY_1[var], width = 0.20, color = \"tab:blue\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx + 0.125, DF_AV_1[var], width = 0.20, color = \"tab:orange\", alpha = 0.8, label = \"LPA-ARO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_TV_1[var], width = 0.20, color = \"tab:orange\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO (V)\")\n",
    "    ax[1].plot(xx, DF_AY_1[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[0].set_xticklabels([])\n",
    "    ax[1].set_xticklabels([\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land \\n boundary\",\n",
    "                           \"seaice/water \\n boundary\"], rotation = 0, wrap = True)\n",
    "    ax[i].tick_params(axis='x', labelsize=20)\n",
    "ax[1].legend(bbox_to_anchor=(1., 1.45), frameon = False)\n",
    "\n",
    "xx == np.arange(-1, 11, 1)\n",
    "yy = np.zeros([xx.size])\n",
    "ax[0].plot(xx, yy, 'k')\n",
    "#ax[1].set_ylim([0, 0.1])\n",
    "fig.suptitle(\"> 0.1 & < 1.0\")\n",
    "fig.savefig(\"ARO_TRO_v_vh_1.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(1, 9, 1)\n",
    "fig, ax = plt.subplots(2, 1, figsize = [16, 8])\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, var in enumerate([\"Bias\", \"MAE\"]):\n",
    "    ax[i].bar(xx - 0.25, DF_AY_2[var], width = 0.20, color = \"tab:blue\", alpha = 0.8, label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx - 0.125, DF_TY_2[var], width = 0.20, color = \"tab:blue\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx + 0.125, DF_AV_2[var], width = 0.20, color = \"tab:orange\", alpha = 0.8, label = \"LPA-ARO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_TV_2[var], width = 0.20, color = \"tab:orange\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO (V)\")\n",
    "    ax[1].plot(xx, DF_AY_2[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[0].set_xticklabels([])\n",
    "    ax[1].set_xticklabels([\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land \\n boundary\",\n",
    "                           \"seaice/water \\n boundary\"], rotation = 0, wrap = True)\n",
    "    ax[i].tick_params(axis='x', labelsize=20)\n",
    "ax[1].legend(bbox_to_anchor=(1., 1.45), frameon = False)\n",
    "\n",
    "xx == np.arange(-1, 11, 1)\n",
    "yy = np.zeros([xx.size])\n",
    "ax[0].plot(xx, yy, 'k')\n",
    "#ax[1].set_ylim([0, 0.1])\n",
    "#fig.suptitle(\"All data\")\n",
    "fig.savefig(\"ARO_TRO_v_vh.pdf\", bbox_inches = \"tight\")\n",
    "fig.suptitle(\"IWP > 1 kg/m2\")\n",
    "fig.savefig(\"ARO_lpa_esa_cloudy.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(1, 9, 1)\n",
    "fig, ax = plt.subplots(2, 1, figsize = [16, 8])\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, var in enumerate([\"Bias\", \"MAE\"]):\n",
    "    ax[i].bar(xx - 0.25, DF_AY[var], width = 0.20, color = \"tab:blue\", alpha = 0.8, label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx - 0.125, DF_TY[var], width = 0.20, color = \"tab:blue\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx + 0.125, DF_AV[var], width = 0.20, color = \"tab:orange\", alpha = 0.8, label = \"LPA-ARO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_TV[var], width = 0.20, color = \"tab:orange\", hatch = \"///\", alpha = 0.8, label = \"LPA-TRO (V)\")\n",
    "    ax[1].plot(xx, DF_AY[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[0].set_xticklabels([])\n",
    "    ax[1].set_xticklabels([\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land \\n boundary\",\n",
    "                           \"seaice/water \\n boundary\"], rotation = 0, wrap = True)\n",
    "    ax[i].tick_params(axis='x', labelsize=20)\n",
    "ax[1].legend(bbox_to_anchor=(1., 1.45), frameon = False)\n",
    "\n",
    "xx == np.arange(-1, 11, 1)\n",
    "yy = np.zeros([xx.size])\n",
    "ax[0].plot(xx, yy, 'k')\n",
    "#ax[1].set_ylim([0, 0.1])\n",
    "#fig.suptitle(\"All data\")\n",
    "fig.savefig(\"ARO_TRO_v_vh.pdf\", bbox_inches = \"tight\")\n",
    "fig.suptitle(\"IWP < 0.1 kg/m2\")\n",
    "fig.savefig(\"ARO_lpa_esa_clear.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx = np.arange(1, 9, 1)\n",
    "fig, ax = plt.subplots(4, 3 , figsize = [32, 24])\n",
    "ax = ax.ravel()\n",
    "\n",
    "\n",
    "for i, var in enumerate([\"Bias\", \"MAE\", \"RMSD\"]):\n",
    "    ax[i].bar(xx - 0.25, DF_TY[var], width = 0.20, color = \"lightsteelblue\",\n",
    "              hatch = \"///\",alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx - 0.125, DF_AY[var], width = 0.20, color = \"tab:blue\",  alpha = 0.8,\n",
    "              label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx + 0.125, DF_TV[var], width = 0.20, color = \"indianred\", hatch = \"///\",\n",
    "              alpha = 0.8, label = \"LPA-TRO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_AV[var], width = 0.20, color = \"tab:red\",  alpha = 0.8, \n",
    "              label = \"LPA-ARO (V)\")\n",
    "    ax[1].plot(xx, DF_AY[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[i].set_title(\"All data\")\n",
    "    ax[0].plot(xx, yy, 'k')\n",
    "    ax[i].set_xticklabels([])\n",
    "    \n",
    "    \n",
    "for i, var in enumerate([\"Bias\", \"MAE\", \"RMSD\"]):\n",
    "    i = i + 3\n",
    "    ax[i].bar(xx - 0.25, DF_TY_3[var], width = 0.20, color = \"lightsteelblue\", hatch = \"///\",\n",
    "              alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx - 0.125, DF_AY_3[var], width = 0.20, color = \"tab:blue\", alpha = 0.8, \n",
    "              label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx + 0.125, DF_TV_3[var], width = 0.20, color = \"indianred\", hatch = \"///\",\n",
    "              alpha = 0.8, label = \"LPA-TRO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_AV_3[var], width = 0.20, color = \"tab:red\", alpha = 0.8, \n",
    "              label = \"LPA-ARO (V)\")\n",
    "    ax[4].plot(xx, DF_AY_3[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[i].set_title(\"IWP < 0.01 kg m$^{-2}$\")\n",
    "    ax[3].plot(xx, yy, 'k')\n",
    "    ax[i].set_xticklabels([])\n",
    "    \n",
    "    \n",
    "for i, var in enumerate([\"Bias\", \"MAE\", \"RMSD\"]):\n",
    "    i = i + 6\n",
    "    ax[i].bar(xx - 0.25, DF_TY_1[var], width = 0.20, color = \"lightsteelblue\", alpha = 0.8, \n",
    "              hatch = \"///\", label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx - 0.125, DF_AY_1[var], width = 0.20, color = \"tab:blue\", alpha = 0.8,\n",
    "              label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx + 0.125, DF_TV_1[var], width = 0.20, color = \"indianred\", hatch = \"///\",\n",
    "              alpha = 0.8, label = \"LPA-TRO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_AV_1[var], width = 0.20, color = \"tab:red\",  alpha = 0.8, \n",
    "              label = \"LPA-ARO (V)\")\n",
    "    ax[7].plot(xx, DF_AY_1[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[i].set_title(r\" 0.01 < IWP < 0.5 kg m$^{-2}$\")\n",
    "    ax[6].plot(xx, yy, 'k')\n",
    "    ax[i].set_xticklabels([])\n",
    "    \n",
    "    \n",
    "for i, var in enumerate([\"Bias\", \"MAE\", \"RMSD\"]):\n",
    "    i = i+ 9\n",
    "    ax[i].bar(xx - 0.25, DF_TY_2[var], width = 0.20, color = \"lightsteelblue\", hatch = \"///\",\n",
    "              alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx - 0.125, DF_AY_2[var], width = 0.20, color = \"tab:blue\", alpha = 0.8, \n",
    "              label = \"LPA-ARO\")\n",
    "    ax[i].bar(xx + 0.125, DF_TV_2[var], width = 0.20, color = \"indianred\", alpha = 0.8, hatch = \"///\",\n",
    "              label = \"LPA-TRO (V)\")\n",
    "    ax[i].bar(xx + 0.25, DF_AV_2[var], width = 0.20, color = \"tab:red\", alpha = 0.8,\n",
    "              label = \"LPA-ARO (V)\")\n",
    "    ax[10].plot(xx, DF_AY_2[\"Mean\"], 'x', c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)  \n",
    "    ax[i].set_title(r\" IWP > 0.5 kg m$^{-2}$\") \n",
    "    ax[9].plot(xx, yy, 'k')\n",
    "    \n",
    "    \n",
    "\n",
    "    ax[9].set_xticklabels([\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land \\n boundary\",\n",
    "                           \"seaice/water \\n boundary\"], rotation = 50)\n",
    "    ax[10].set_xticklabels([\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land \\n boundary\",\n",
    "                           \"seaice/water \\n boundary\"], rotation = 50)   \n",
    "    ax[11].set_xticklabels([\"all\",\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\", \"snow/land \\n boundary\",\n",
    "                           \"seaice/water \\n boundary\"], rotation = 50)\n",
    "    ax[i].tick_params(axis='x', labelsize=18)\n",
    "ax[1].legend(loc = \"center left\", frameon = False)\n",
    "\n",
    "xx == np.arange(-1, 11, 1)\n",
    "yy = np.zeros([xx.size])\n",
    "ax[0].plot(xx, yy, 'k')\n",
    "#ax[1].set_ylim([0, 0.1])\n",
    "#fig.suptitle(\"All data\")\n",
    "\n",
    "\n",
    "fig.savefig(\"ARO_TRO_v_vh.pdf\", bbox_inches = \"tight\")\n",
    "#fig.suptitle(\"IWP < 0.1 kg/m2\")\n",
    "#fig.savefig(\"ARO_lpa_clear.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig. 11 of manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "counts = [stype.size]\n",
    "for i in [0, 1, 2, 3, 4, 6, 7]:\n",
    "    mask = stype == i\n",
    "    counts.append(np.sum(mask))\n",
    " \n",
    "counts = np.array(counts)\n",
    "\n",
    "xx = np.arange(1, 5, 1)\n",
    "fig, ax = plt.subplots(1, 2 , figsize = [16, 8])\n",
    "ax = ax.ravel()\n",
    "\n",
    "\n",
    "for i, var in enumerate([\"Bias\", \"MAE\"]):\n",
    "    ax[i].bar(xx - 0.15, DF_TY[1:5][var], yerr = std_t[i, :], ecolor='black', capsize=10, width = 0.30, color = \"lightsteelblue\",\n",
    "              hatch = \"///\",alpha = 0.8, label = \"LPA-TRO\")\n",
    "    ax[i].bar(xx + 0.15, DF_AY[1:5][var], yerr = std_a[i, :], ecolor='black', capsize=10, width = 0.30, color = \"tab:blue\",  alpha = 0.8,\n",
    "              label = \"LPA-aARO\")\n",
    "\n",
    "    ax[1].plot(xx, DF_AY[1:5][\"Mean\"], 'x',  c = \"k\")\n",
    "    #ax[i].set_xlabel(\"Subsets\")\n",
    "    ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "    plt.tight_layout(pad = 0.5)\n",
    "    ax[i].set_xticks(xx)\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "    ax[i].set_xticklabels([])\n",
    "ax[1].errorbar(xx, DF_AY[1:5][\"Mean\"],color = \"k\", yerr = std_a[3, :], ecolor='black', capsize=10, fmt = 'x')\n",
    "\n",
    "ax[0].legend(loc = \"upper left\", frameon = False)\n",
    "\n",
    "xx == np.arange(-1, 4, 1)\n",
    "yy = np.zeros([xx.size])\n",
    "ax[0].plot(xx, yy, 'k')\n",
    "#ax[1].set_ylim([0, 0.1])\n",
    "#fig.suptitle(\"All data\")\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xticklabels([\"water\", \"land\", \"snow-cover\", \"sea ice\", ])\n",
    "    #\"coastlines\", \"snow/land \\n boundary\",\n",
    "    #                       \"seaice/water \\n boundary\"], rotation = 50)\n",
    "\n",
    "ax[0].text(0.5, 0.037, \"a)\")\n",
    "ax[1].text(0.5, 0.118, \"b)\")\n",
    "fig.savefig(\"ARO_TRO_v_vh_all.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_data      = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train_jan_lpa.nc\"), \n",
    "                             inputs, \n",
    "                             outputs,\n",
    "                             batch_size = batchSize,\n",
    "                             latlims = latlims,)\n",
    "                             #log_iwp = xlog)\n",
    "    \n",
    "pr1_data      = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train_jan_lpa_pr1.nc\"), \n",
    "                             inputs, \n",
    "                             outputs,\n",
    "                             batch_size = batchSize,\n",
    "                             latlims = latlims,)\n",
    "                             #log_iwp = xlog)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_data      = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train_jan_lpa.nc\"), \n",
    "                             inputs, \n",
    "                             outputs,\n",
    "                             batch_size = batchSize,\n",
    "                             latlims = latlims,)\n",
    "                             #log_iwp = xlog)\n",
    "    \n",
    "pr1_data      = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train_jan_lpa_pr1.nc\"), \n",
    "                             inputs, \n",
    "                             outputs,\n",
    "                             batch_size = batchSize,\n",
    "                             latlims = latlims,)\n",
    "                             #log_iwp = xlog)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = [16, 8])\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "\n",
    "lsm = np.argmax(pr1_data.stype, axis = 1)\n",
    "tb  = pr1_data.add_noise(pr1_data.x[:, :4], [0, 1, 2, 3])\n",
    "mask = (lsm == 0) \n",
    "\n",
    "lsm1 = np.argmax(lpa_data.stype, axis = 1)\n",
    "tb1  = lpa_data.add_noise(lpa_data.x[:, :4], [0, 1, 2, 3])\n",
    "mask1 = (lsm == 0) \n",
    "\n",
    "ax[0].scatter(tb[mask, 0], pr1_data.y.ravel()[mask], c = \"k\", s = 3, label = \"TRO\")\n",
    "ax[1].scatter(tb1[mask1, 1], lpa_data.y.ravel()[mask1],c = \"r\", s = 3, label = \"ARO\")\n",
    "\n",
    "\n",
    "ax[1].scatter(tb[mask, 1], pr1_data.y.ravel()[mask], c= \"k\", s = 3, label = \"TRO\")\n",
    "ax[0].scatter(tb1[mask1, 0], lpa_data.y.ravel()[mask1],\n",
    "              c ='r', s = 3, label = \"ARO\")\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].legend()\n",
    "    #ax[1].legend()\n",
    "    ax[0].set_xlabel(\"TB 166V GHz [K]\")\n",
    "    ax[1].set_xlabel(\"TB 166H GHz [K]\")\n",
    "    ax[0].set_ylabel(r\"IWP [kg m$^{-2}$]\")\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "fig.savefig(\"IWP_TB_relationship_VH.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbbins = np.arange(100, 300, 10)\n",
    "tbbins_c = (tbbins[1:] + tbbins[:-1])/2\n",
    "\n",
    "def get_mean_iwp(t, tbbins, iwp):\n",
    "    \n",
    "    itb = np.digitize(t, tbbins)\n",
    "    imean = np.bincount(itb, iwp)/np.bincount(itb)\n",
    "    \n",
    "    return imean\n",
    "\n",
    "\n",
    "imean_v = get_mean_iwp(tb1[:, 0], tbbins, lpa_data.y.ravel())\n",
    "imean_h = get_mean_iwp(tb1[:, 1], tbbins, lpa_data.y.ravel())\n",
    "imean_v1 = get_mean_iwp(tb[:, 0], tbbins, pr1_data.y.ravel())\n",
    "imean_h1 = get_mean_iwp(tb[:, 1], tbbins, pr1_data.y.ravel())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "ax.plot(tbbins, imean_v[1:], 'r', label = \"ARO V\")\n",
    "ax.plot(tbbins, imean_v1[1:], 'r--', label  = \"TRO V\")\n",
    "ax.plot(tbbins, imean_h[1:], 'k', label = \"ARO H\")\n",
    "ax.plot(tbbins, imean_h1[1:], 'k--', label  = \"TRO H\")\n",
    "ax.legend()\n",
    "ax.grid(\"on\", alpha = 0.3)\n",
    "ax.set_ylim([1e-4, 17.5])\n",
    "ax.set_xlim([90, 220])\n",
    "\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"TB [K]\")\n",
    "ax.set_ylabel(r\"IWP [kg m$^{-2}$]\")\n",
    "fig.savefig(\"TB_IWP.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbbins_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = [16, 8])\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "\n",
    "lsm = np.argmax(pr1_data.stype, axis = 1)\n",
    "tb  = pr1_data.add_noise(pr1_data.x[:, :4], [0, 1, 2, 3])\n",
    "mask = (lsm == 0) \n",
    "\n",
    "lsm1 = np.argmax(lpa_data.stype, axis = 1)\n",
    "tb1  = lpa_data.add_noise(lpa_data.x[:, :4], [0, 1, 2, 3])\n",
    "mask1 = (lsm == 0) \n",
    "\n",
    "ax[0].scatter(tb[mask, 0] - tb[mask, 1], pr1_data.y.ravel()[mask], c = \"k\", s = 3, label = \"TRO\")\n",
    "ax[1].scatter(tb1[mask1, 0] - tb1[mask1, 1], lpa_data.y.ravel()[mask1],c = \"r\", s = 3, label = \"ARO\")\n",
    "\n",
    "\n",
    "ax[1].scatter(tb[mask, 0] - tb[mask, 1], pr1_data.y.ravel()[mask], c= \"k\", s = 3, label = \"TRO\")\n",
    "ax[0].scatter(tb1[mask1, 0]- tb1[mask1, 1], lpa_data.y.ravel()[mask1],c = \"r\", s = 3, label = \"ARO\")\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].legend()\n",
    "    #ax[1].legend()\n",
    "    ax[0].set_xlabel(\"TB 166V GHz [K]\")\n",
    "    ax[1].set_xlabel(\"TB 166H GHz [K]\")\n",
    "    ax[0].set_ylabel(r\"IWP [kg m$^{-2}$]\")\n",
    "    ax[i].grid(\"on\", alpha = 0.3)\n",
    "fig.savefig(\"IWP_PD_relationship_VH.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = [12, 6])\n",
    "ax = ax.ravel()\n",
    "mask = stype.ravel() == 0\n",
    "ax[0].scatter( TB[:, 2][mask],  AY.ravel()[mask], s = 2, c = \"k\")\n",
    "#ax[0].scatter( TB[:, 0][mask],  TY_mean.ravel()[mask], color = \"r\", s = 2)\n",
    "cs = ax[0].scatter( TB[:, 2][mask],  TY_mean.ravel()[mask], s = 2, \n",
    "             c = \"r\")\n",
    "\n",
    "#cs = ax[1].scatter( TB[:, 0][mask],  AY.ravel()[mask], c = TB[:, 0][mask] - TB[:, 1][mask], \n",
    "#              s = 2, vmin = 1, vmax = 30, cmap = cm.tab20c)\n",
    "\n",
    "\n",
    "\n",
    "ax[0].grid(\"on\", alpha = 0.2)\n",
    "ax[1].grid(\"on\", alpha = 0.2)\n",
    "fig.colorbar(cs, ax = ax)   \n",
    "#ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.wvp.ravel()[mask].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfe( y0, y):\n",
    "    return np.median(10**(np.abs(np.log10(y/y0))) - 1) * 100\n",
    "\n",
    "def calculate_mfe(y0, y):\n",
    "    nbins = 60\n",
    "    logbins = np.log10(np.logspace(np.log10(1e-4), np.log10(1e2), nbins))\n",
    "    ibins = np.digitize(np.log10(y0), logbins)\n",
    "    err = []\n",
    "    for ix in range(nbins):\n",
    "\n",
    "        ix = np.where(ibins == ix)[0]\n",
    "\n",
    "        err.append(mfe(y0[ix], y[ix]))\n",
    "    return err, logbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = [8, 8])\n",
    "fig.tight_layout(pad=1.0)   \n",
    "\n",
    "err, logbins  = calculate_mfe(AY, AY_mean)\n",
    "err1, _ = calculate_mfe(TY, TY_mean)\n",
    "\n",
    "err2, logbins  = calculate_mfe(AV, AV_mean)\n",
    "err3, _ = calculate_mfe(TV, TV_mean)\n",
    "\n",
    "ax.plot(10 ** (logbins[1:]), err[1:], '-', label = \"LPA-ARO\")\n",
    "ax.plot(10 **(logbins[1:]), err1[1:], '-', label = \"LPA-TRO\")\n",
    "\n",
    "ax.plot(10 ** (logbins[1:]), err2[1:], '-', label = \"LPA-ARO (V)\")\n",
    "ax.plot(10 **(logbins[1:]), err3[1:], '-', label = \"LPA-TRO (V)\")\n",
    "\n",
    "ax.set_ylim([0, 500])\n",
    "ax.set_xscale(\"log\")\n",
    "#ax.set_title()\n",
    "ax.set_xlabel(r\" IWP [kg m$^{-2}$] \")\n",
    "ax.set_ylabel(\"Median fractional error [%]\")\n",
    "ax.legend()\n",
    "ax.grid('on')\n",
    "fig.savefig(\"median_fractional_error.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_snow(Y_mean, Y, stype, lat):\n",
    "    statistics_aro = np.zeros([2, 4])\n",
    "    # snow/seaice\n",
    "    #amask = (stype == 2) | (stype == 3) \n",
    "    amask = (stype == 2) & (lat > 45)\n",
    "    statistics_aro[0, :] = stats(Y_mean[amask], Y[amask])\n",
    "\n",
    "    # snow \n",
    "    amask = (stype == 7) & (lat > 45) \n",
    "    statistics_aro[1, :] = stats(Y_mean[amask], Y[amask])\n",
    "    \n",
    "    DF_aro = pd.DataFrame(statistics_aro, columns = [\"Bias\", \"MAE\", \"STD\", \"Mean\"], \n",
    "                  index = [\"snow\",\"land/snow\"])\n",
    "    return DF_aro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_AY = stats_snow(AY_mean, AY, stype, lat)\n",
    "snow_TY   = stats_snow(TY_mean, TY, stype, lat)\n",
    "snow_AV  = stats_snow(AV_mean, AV, stype, lat)\n",
    "snow_TV  = stats_snow(TV_mean, TV, stype, lat)\n",
    "\n",
    "iwpmask = AY < 0.1\n",
    "snow_all_1 = stats_snow(AY_mean[iwpmask], AY[iwpmask], stype[iwpmask], lat[iwpmask])\n",
    "snow_V_1   = stats_snow(V_mean[iwpmask], AY[iwpmask], stype[iwpmask], lat[iwpmask])\n",
    "snow_VH_1  = stats_snow(VH_mean[iwpmask], AY[iwpmask], stype[iwpmask], lat[iwpmask])\n",
    "\n",
    "iwpmask = AY > 0.1\n",
    "snow_all_2 = stats_snow(AY_mean[iwpmask], AY[iwpmask], stype[iwpmask], lat[iwpmask])\n",
    "snow_V_2   = stats_snow(V_mean[iwpmask], AY[iwpmask], stype[iwpmask], lat[iwpmask])\n",
    "snow_VH_2  = stats_snow(VH_mean[iwpmask], AY[iwpmask], stype[iwpmask], lat[iwpmask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_all_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_V_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_VH_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sland_all = stats_snow(AY_mean, AY, stype, lat, a = 7)\n",
    "sland_V   = stats_snow(V_mean, AY, stype, lat, a = 7)\n",
    "sland_VH  = stats_snow(VH_mean, AY, stype, lat, a = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "xx = np.arange(1, 3, 1)\n",
    "fig, ax = plt.subplots(1, 3, figsize = [12, 4])\n",
    "ax = ax.ravel()\n",
    "\n",
    "var = \"Bias\"\n",
    "i = 0\n",
    "ax[i].bar(xx - 0.1, snow_all[var], width = 0.05, color = \"tab:blue\", alpha = 0.8, label = \"LPA ARO (VH)\")\n",
    "ax[i].bar(xx , snow_V[var], width = 0.05, color = \"tab:red\", alpha = 0.8, label = \"LPA ARO (V)\")\n",
    "ax[i].bar(xx + 0.1, snow_VH[var], width = 0.05, color = \"tab:green\", alpha = 0.8, label = \"LPA ARO (VH/2)\")\n",
    "#ax[i].set_xlabel(\"Subsets\")\n",
    "#ax[1].plot(xx, snow_all[\"Mean\"], 'x', c = \"k\")\n",
    "ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "plt.tight_layout(pad = 0.5)\n",
    "ax[i].set_xticks(xx)\n",
    "ax[i].set_xticklabels([\"snow\",\"land/snow\"], rotation = 50)\n",
    "ax[i].tick_params(axis='x', labelsize=12)\n",
    "ax[i].grid(\"on\")   \n",
    "ax[i].set_title(\"All\")\n",
    "\n",
    "i = 1\n",
    "ax[i].bar(xx - 0.1, snow_all_1[var], width = 0.05, color = \"tab:blue\", alpha = 0.8, label = \"LPA ARO (VH)\")\n",
    "ax[i].bar(xx , snow_V_1[var], width = 0.05, color = \"tab:red\", alpha = 0.8, label = \"LPA ARO (V)\")\n",
    "ax[i].bar(xx + 0.1, snow_VH_1[var], width = 0.05, color = \"tab:green\", alpha = 0.8, label = \"LPA ARO (VH/2)\")\n",
    "#ax[i].set_xlabel(\"Subsets\")\n",
    "#ax[1].plot(xx, snow_all[\"Mean\"], 'x', c = \"k\")\n",
    "ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "plt.tight_layout(pad = 0.5)\n",
    "ax[i].set_xticks(xx)\n",
    "ax[i].set_xticklabels([\"snow\",\"land/snow\"], rotation = 50)\n",
    "ax[i].tick_params(axis='x', labelsize=12)\n",
    "ax[i].grid(\"on\")\n",
    "ax[i].set_title(\"IWP < 0.1 kg/m2\")\n",
    "\n",
    "i = 2\n",
    "ax[i].bar(xx - 0.1, snow_all_2[var], width = 0.05, color = \"tab:blue\", alpha = 0.8, label = \"LPA ARO (VH)\")\n",
    "ax[i].bar(xx , snow_V_2[var], width = 0.05, color = \"tab:red\", alpha = 0.8, label = \"LPA ARO (V)\")\n",
    "ax[i].bar(xx + 0.1, snow_VH_2[var], width = 0.05, color = \"tab:green\", alpha = 0.8, label = \"LPA ARO (VH/2)\")\n",
    "#ax[i].set_xlabel(\"Subsets\")\n",
    "#ax[1].plot(xx, snow_all[\"Mean\"], 'x', c = \"k\")\n",
    "ax[i].set_ylabel(var + r\" [kg m$^{-2}$]\")\n",
    "plt.tight_layout(pad = 0.5)\n",
    "ax[i].set_xticks(xx)\n",
    "ax[i].set_xticklabels([\"snow\",\"land/snow\"], rotation = 50)\n",
    "ax[i].tick_params(axis='x', labelsize=12)\n",
    "ax[i].grid(\"on\")    \n",
    "ax[0].legend(prop={'size': 12})\n",
    "yy = np.zeros(xx.shape)\n",
    "ax[0].plot(xx, yy, 'k--')\n",
    "ax[i].set_title(\"IWP > 0.1 kg/m2\")\n",
    "fig.savefig(\"snow_lpa.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amask = (stype == 2) & (TB[:, 0, :] > 250) & (TB[:, 0, :] < 275) & (AY < 0.1)\n",
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "ax.scatter(AY_mean[amask], V_mean[amask])\n",
    "\n",
    "x = np.arange(0, 4)\n",
    "ax.plot(x, x, 'k')\n",
    "ax.set_xlim([0.0001, 5])\n",
    "ax.set_ylim([0.0001, 5])\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale(\"log\")\n",
    "np.mean(VH_mean[amask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats(amask1, fig, ax, c, offset, labels, figname = \"statistics.png\"):\n",
    "    statistics_aro = np.zeros([prbins.size - 1, 3])\n",
    "    statistics_tro = np.zeros([prbins.size - 1, 3])\n",
    "    npr            = np.zeros([prbins.size - 1])\n",
    "    for i in range(1, prbins.size):\n",
    "        amask = ipr == i\n",
    "        amask = np.logical_and(amask, amask1)\n",
    "        statistics_aro[i-1, :] = stats(AY_mean[amask], AY[amask])\n",
    "        statistics_tro[i-1, :] = stats(TY_mean[amask], TY[amask])\n",
    "        npr[i-1]               = np.sum(amask)\n",
    "\n",
    "    DF_tro = pd.DataFrame(statistics_tro, columns = [\"Bias\", \"MAE\", \"RMSD\"], \n",
    "                      index = prcenter)\n",
    "    DF_aro = pd.DataFrame(statistics_aro, columns = [\"Bias\", \"MAE\", \"RMSD\"], \n",
    "                      index = prcenter)\n",
    "\n",
    "\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for i, key in enumerate([\"Bias\", \"MAE\", \"RMSD\" ]):\n",
    "\n",
    "        ax[i].plot(DF_tro[key], \"-o\", color = c, label = labels[0])\n",
    "        ax[i].plot(DF_aro[key], \"--o\", color = c, label = labels[1])\n",
    "        ax[i].legend()\n",
    "        ax[i].set_ylabel(key + \" [kg/m2]\")\n",
    "        ax[i].set_xlabel(\"pratio-gmi\")\n",
    "\n",
    "        plt.tight_layout(pad = 0.5)\n",
    "    ax[3].bar(prcenter + offset, npr, width = 0.02 , color = c)  \n",
    "    ax[3].set_xlabel(\"pratio-gmi\")\n",
    "    ax[3].set_ylabel(\"counts\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prbins   = np.arange(1, 1.4, 0.06)\n",
    "prcenter = (prbins[1:] + prbins[:-1]) * 0.5\n",
    "\n",
    "ipr   = np.digitize(PR, prbins)\n",
    "npr   = np.zeros([prbins.size])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize = [24, 8])\n",
    "\n",
    "amask1 = stype > -1\n",
    "\n",
    "colors = [\"#e41a1c\", \"#377eb8\", \"#4daf4a\"]\n",
    "\n",
    "#984ea3\n",
    "#ff7f00\n",
    "#ffff33\n",
    "#a65628\n",
    "#f781bf]\n",
    "plot_stats(amask1, fig, ax ,c = colors[0], offset = -0.01, labels = [\"tro_all\", \"aro_all\"],\n",
    "           figname = \"statistics_all.png\")\n",
    "\n",
    "\n",
    "amask1 = stype == 0\n",
    "plot_stats(amask1, fig, ax, c = colors[1], offset = 0, labels = [\"tro_water\", \"aro_water\"],\n",
    "           figname = \"statistics_water.png\")\n",
    "\n",
    "amask1 = stype == 1\n",
    "plot_stats(amask1, fig, ax, c = colors[2], offset = 0.01, labels = [\"tro_land\", \"aro_land\"],\n",
    "           figname = \"statistics_land.png\")\n",
    "\n",
    "\n",
    "ax[3].legend([\"all\", \"water\", \"land\"])\n",
    "fig.savefig(\"statistics_surfacetype.png\", bbox_inches = \"tight\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize = [24, 8])\n",
    "amask1 = np.abs(lat) <= 30.0\n",
    "plot_stats(amask1, fig, ax,  c = colors[0], offset = -0.01, labels = [r\"tro 0$^{\\circ}$ - 30$^{\\circ}$\",\n",
    "                                             r\"aro 0$^{\\circ}$ - 30$^{\\circ}$\"\n",
    "                                            ])\n",
    "\n",
    "\n",
    "amask1 = (np.abs(lat) > 30) & (np.abs(lat) <= 45)\n",
    "plot_stats(amask1, fig, ax,  c = colors[1], offset = 0, labels = [r\"tro 30$^{\\circ}$ - 45$^{\\circ}$\",\n",
    "                                             r\"aro 30$^{\\circ}$ - 45$^{\\circ}$\"\n",
    "                                            ])\n",
    "\n",
    "amask1 = (np.abs(lat) > 45) \n",
    "plot_stats(amask1, fig, ax, c = colors[2], offset = 0.01, labels = [r\"tro 45$^{\\circ}$ - 65$^{\\circ}$\",\n",
    "                                             r\"aro 45$^{\\circ}$ - 65$^{\\circ}$\"\n",
    "                                            ])\n",
    "\n",
    "ax[3].legend([r\"0$^{\\circ}$ - 30$^{\\circ}$\", \n",
    "              r\"30$^{\\circ}$ - 45$^{\\circ}$\",\n",
    "              r\"45$^{\\circ}$ - 65$^{\\circ}$\"])\n",
    "fig.savefig(\"statistics_latitudes.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sigma(tb):\n",
    "    \"\"\"\n",
    "    three sigma rule to classify cloudy and clear-sky tb\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tb : 183+-3 GHz \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : scalar, the threshold value\n",
    "    \"\"\"\n",
    "    bins = np.arange(100, 310, 1)\n",
    "    hist = np.histogram(tb, bins, density = True)\n",
    "\n",
    "\n",
    "    mids = 0.5*(bins[1:] + bins[:-1])\n",
    "\n",
    "    tbmean = np.sum(hist[0] * mids)\n",
    "\n",
    "    sd  = np.sqrt(np.sum(hist[0] * (mids - tbmean)**2))\n",
    "\n",
    "    tbmax = mids[np.argmax(hist[0])]\n",
    "    \n",
    "    mask = tbmax-3*sd\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbt    = three_sigma(tb)\n",
    "amask1 = tb[:, 3] < tbt\n",
    "amask1 = np.repeat(amask1.reshape(-1, 1), 4, axis = 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize = [24, 8])\n",
    "plot_stats(amask1, fig, ax, c = colors[0], labels = [\"tro_cloudy\", \"aro_cloudy\"], offset = -0.01)\n",
    "\n",
    "amask1 = tb[:, 3] > tbt\n",
    "\n",
    "amask1 = np.repeat(amask1.reshape(-1, 1), 4, axis = 1)\n",
    "\n",
    "plot_stats(amask1, fig, ax, c = colors[1], labels = [\"tro_clear\", \"aro_clear\"], offset = 0,)\n",
    "\n",
    "ax[3].legend([\"cloudy\", \"clear\"])\n",
    "ax[3].set_yscale(\"log\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[2].set_yscale(\"log\")\n",
    "fig.savefig(\"statistics_cloudyclear.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDF_uncertainty_bins(y_pre, y0, ulim):\n",
    "    dtb =(y_pre[:, imedian] - y0)\n",
    "    uncertain = y_pre[:, -13] - y_pre[:, 12]\n",
    "\n",
    "    \n",
    "    im = uncertain <= ulim[0]\n",
    "    print (np.sum(im), uncertain.max(), uncertain.min())\n",
    "    bins = np.arange(-12.5, 15., 0.8)\n",
    "    hist0 = np.histogram(dtb[im], bins, density = True)\n",
    "    \n",
    "    \n",
    "    im = np.logical_and((uncertain < ulim[1]), ( uncertain >= ulim[0]) )\n",
    "    hist1 = np.histogram(dtb[im], bins, density = True)\n",
    " \n",
    "  \n",
    "    im = uncertain >=ulim[1]\n",
    "    hist2 = np.histogram(dtb[im], bins, density = True)\n",
    "    \n",
    "    \n",
    "    return hist0[0], hist1[0],  hist2[0], bins\n",
    "\n",
    "def count_true_events(y_pre, y0, ulim):\n",
    "    \n",
    "    dtb =(y_pre[:, 3] - y0)\n",
    "    uncertain = y_pre[:, 5] - y_pre[:, 1]\n",
    " #I1V\n",
    "    #ulim = [3, 4] #I2V\n",
    "    #ulim = [1, 1.5 ]#I3V\n",
    "    \n",
    "    im = uncertain <= ulim[0]\n",
    "    \n",
    "    mask = np.logical_and(y0[im] >= y_pre[im, 1],  y0[im] <= y_pre[im, 5])\n",
    "    icount1 = np.sum(mask)\n",
    "    icount1 = icount1/np.sum(im) * 100\n",
    "    \n",
    "    \n",
    "    im = np.logical_and((uncertain < ulim[1]), ( uncertain >= ulim[0]) )\n",
    "    mask = np.logical_and(y0[im] >= y_pre[im, 1],  y0[im] <= y_pre[im, 5])\n",
    "    icount2 = np.sum(mask)\n",
    "    icount2 = icount2/np.sum(im) * 100\n",
    "    \n",
    " \n",
    "  \n",
    "    im = uncertain >=ulim[1]\n",
    "    mask = np.logical_and(y0[im] >= y_pre[im, 1],  y0[im] <= y_pre[im, 5])\n",
    "    icount3 = np.sum(mask)\n",
    "    icount3 = icount3/np.sum(im) * 100\n",
    "    \n",
    "    return np.round(icount1, 1), np.around(icount2, 1), np.round(icount3,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness(y, mask = None):\n",
    "    if mask is not None:\n",
    "        s = np.mean((y[mask, -2] - y[mask, 1])/y[mask, imedian])\n",
    "    else:\n",
    "        s = np.mean((y[:, -2] - y[:, 1])/y[:, imedian])        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpness(AY_pre, amask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpness(ty_pre, amask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(y_pre, y):\n",
    "    n_intervals = len(quantiles)//2\n",
    "    qs = quantiles\n",
    "    total = 0.0\n",
    "    intervals = np.array([q_r - q_l for (q_l, q_r) in zip(qs, reversed(qs))])[:n_intervals]\n",
    "    counts = np.zeros(n_intervals)\n",
    "    \n",
    "    for i in range(n_intervals):\n",
    "        l = y_pre[:, i]\n",
    "        r = y_pre[:, -(i + 1)]\n",
    "        counts[i] += np.logical_and(y >= l, y < r).sum()\n",
    "\n",
    "    total += np.prod(y.size)\n",
    "\n",
    "    return intervals[::-1], (counts / total)[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amask = stype == 0\n",
    "amask1 = np.abs(lat) <= 30.0\n",
    "\n",
    "amask = np.logical_and(amask, amask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic(y_pre, y, iupper, ilower, interval):\n",
    "    upper      = y_pre[:, iupper]\n",
    "    lower      = y_pre[:, ilower]\n",
    "    alpha      = 1 - interval/100\n",
    "\n",
    "    truevalues = y\n",
    "    I1         = np.where(truevalues < lower, 1, 0)\n",
    "    I2         = np.where(truevalues > upper, 1, 0)\n",
    "    \n",
    "    score      = (upper - lower) + 2/alpha * (lower - truevalues) * I1 + 2/alpha * (truevalues - upper) * I2\n",
    "    \n",
    "    return np.mean(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amask = stype == 0\n",
    "amask1 = np.abs(lat) <= 30.0\n",
    "\n",
    "amask = np.logical_and(amask, amask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ay_pre = AY_pre.reshape(-1, 50)\n",
    "ty_pre = TY_pre.reshape(-1, 50)\n",
    "ay     = AY.ravel()\n",
    "ty     = TY.ravel()\n",
    "mask   = amask.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascores = []\n",
    "tscores = []\n",
    "ascores_all = []\n",
    "tscores_all = []\n",
    "intervals = []\n",
    "for i in range(25):\n",
    "    ilower = i\n",
    "    iupper = -1 - i\n",
    "    interval = (quantiles[iupper] - quantiles[ilower]) * 100\n",
    "    \n",
    "    intervals.append(interval)\n",
    "    \n",
    "    ascores.append(aic(ay_pre[mask, :], ay[mask], iupper, ilower, interval))\n",
    "    tscores.append(aic(ty_pre[mask, :], ty[mask], iupper, ilower, interval))\n",
    "    ascores_all.append(aic(ay_pre, ay, iupper, ilower, interval))\n",
    "    tscores_all.append(aic(ty_pre, ty, iupper, ilower, interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "ax.plot(intervals, ascores_all, \"--\", label = \"aro\", color = \"tab:blue\")\n",
    "ax.plot(intervals, tscores_all, \"-\", label = \"tro\", color = \"tab:blue\")\n",
    "ax.plot(intervals, ascores, \"--\", label = \"aro subset\", color = \"tab:red\")\n",
    "ax.plot(intervals, tscores, \"-\", label = \"tro subset\", color = \"tab:red\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"interval range [%]\")\n",
    "ax.set_ylabel(\"average interval score\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"interval range [%]\")\n",
    "ax.set_ylabel(\"average interval score\")\n",
    "#ax.set_title(\"All data\")\n",
    "ax.set_title(\"water + tropics\")\n",
    "plt.tight_layout(pad = 0.5)\n",
    "fig.savefig(\"AIS.png\", bbox_inches = \"tight\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = [6, 6])\n",
    "\n",
    "\n",
    "inter, fre = calibration(ay_pre, ay )\n",
    "\n",
    "ax.plot(inter, fre, label = \"ARO\")\n",
    "\n",
    "inter, fre = calibration(ty_pre, ty )\n",
    "\n",
    "ax.plot(inter, fre, label = \"TRO\")\n",
    "\n",
    "inter, fre = calibration(ay_pre[mask, :], ay[mask] )\n",
    "\n",
    "ax.plot(inter, fre, label = \"ARO subset\")\n",
    "\n",
    "inter, fre = calibration(ty_pre[mask, :], ty[mask] )\n",
    "\n",
    "ax.plot(inter, fre, label = \"TRO subset\")\n",
    "\n",
    "ax.legend()\n",
    "y = np.arange(0, 1.2, 0.2)\n",
    "x = y\n",
    "\n",
    "ax.plot(x, y, \"k--\")\n",
    "ax.set_xlabel(\"Observed\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "fig.savefig(\"calibration.png\", bbox_inches = \"tight\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonal_mean(lat, iwp, latbins):\n",
    "    \n",
    "\n",
    "    bins     = np.digitize(lat, latbins)\n",
    "    \n",
    "    nbins    = np.bincount(bins)\n",
    "    iwp_mean = np.bincount(bins, iwp)\n",
    "    \n",
    "    return iwp_mean, nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latbins = np.arange(-65, 65, 1.5)\n",
    "\n",
    "iwp_tro, counts_t = zonal_mean(lat.ravel(), TY_mean.ravel(), latbins)\n",
    "iwp_aro, counts_a = zonal_mean(lat.ravel(), AY_mean.ravel(), latbins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = [5, 8])\n",
    "ax.plot( iwp_tro[1:]/counts_t[1:], latbins, \"-\", color = \"tab:blue\", label = \"tro\")\n",
    "ax.plot( iwp_aro[1:]/counts_a[1:], latbins, \"--\",color = \"tab:blue\", label = \"aro\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"IWP [kg m$^{-2}$]\")\n",
    "ax.set_ylabel(\"Latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwp_aro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latbins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
