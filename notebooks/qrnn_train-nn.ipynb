{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "processed-stations",
   "metadata": {},
   "source": [
    "## Notebook to retrieve IWP from GMI TB and other auxiliary data using QRNN, uses quantNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "funky-outdoors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import ipywidgets as w\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "\n",
    "from quantnn.metrics import ScatterPlot\n",
    "from quantnn.models.pytorch.logging import TensorBoardLogger\n",
    "from quantnn.transformations import LogLinear, Log, Log10, Id\n",
    "\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from iwc2tb.GMI.gmiData import gmiData\n",
    "import os\n",
    "import time\n",
    "from quantnn.models.pytorch.fully_connected import FullyConnected\n",
    "from torch import optim\n",
    "from quantnn.qrnn import QRNN\n",
    "from torch.optim import Adam\n",
    "\n",
    "import time\n",
    "#time.sleep(60 * 60 * 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-salon",
   "metadata": {},
   "source": [
    "### Set Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "specialized-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles         = np.linspace(0.01, 0.99, 51)\n",
    "\n",
    "#quantiles         =  np.array([0.2, 3 , 16 ,50 ,84 ,97, 99.8])\n",
    "\n",
    "batchSize         = 256\n",
    "\n",
    "\n",
    "n_layers          = 5\n",
    "n_neurons         = 256\n",
    "\n",
    "\n",
    "#inputs            = np.array([\"ta\", \"t2m\",  \"wvp\", \"z0\", \"lat\", \"stype\"])\n",
    "inputs            = np.array([\"ta\", \"t2m\",  \"wvp\", \"z0\", \"stype\"])\n",
    "ninputs           = len(inputs) + 2 + 7\n",
    "\n",
    "outputs           = \"iwp\"\n",
    "\n",
    "latlims           = [0, 65]\n",
    "\n",
    "\n",
    "#outputfile        = os.path.join(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/try_training/\"), \n",
    "#                                                    filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precious-extra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01  , 0.0296, 0.0492, 0.0688, 0.0884, 0.108 , 0.1276, 0.1472,\n",
       "       0.1668, 0.1864, 0.206 , 0.2256, 0.2452, 0.2648, 0.2844, 0.304 ,\n",
       "       0.3236, 0.3432, 0.3628, 0.3824, 0.402 , 0.4216, 0.4412, 0.4608,\n",
       "       0.4804, 0.5   , 0.5196, 0.5392, 0.5588, 0.5784, 0.598 , 0.6176,\n",
       "       0.6372, 0.6568, 0.6764, 0.696 , 0.7156, 0.7352, 0.7548, 0.7744,\n",
       "       0.794 , 0.8136, 0.8332, 0.8528, 0.8724, 0.892 , 0.9116, 0.9312,\n",
       "       0.9508, 0.9704, 0.99  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.01, 0.99, 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-corpus",
   "metadata": {},
   "source": [
    "## read in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "returning-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (268.5665796717347, 20.29343380365656), 1: (264.9757803213727, 23.312992560374052), 2: (265.45348009405046, 13.75845443481109), 3: (257.0582191483074, 9.455841612721185), 4: (286.3129319424382, 14.495873546238812), 5: (22.564311828462827, 16.375402352734177), 6: (164.17300322756427, 452.12711641524135)}\n",
      "{0: (268.5665796717347, 20.29343380365656), 1: (264.9757803213727, 23.312992560374052), 2: (265.45348009405046, 13.75845443481109), 3: (257.0582191483074, 9.455841612721185), 4: (286.3129319424382, 14.495873546238812), 5: (22.564311828462827, 16.375402352734177), 6: (164.17300322756427, 452.12711641524135)}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "data = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train_jan_esa.nc\"), \n",
    "               inputs, outputs, latlims = latlims, pratio = None,\n",
    "               batch_size = batchSize, transform = None)  \n",
    "\n",
    "norm = data.norm\n",
    "\n",
    "validation_data = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_test_jan_esa.nc\"), \n",
    "               inputs, outputs, latlims = latlims, normalise = norm, pratio = None,\n",
    "               batch_size = batchSize, transform = None)  \n",
    "\n",
    "\n",
    "training_data      = DataLoader(data, batch_size=None, num_workers=1, pin_memory=True)\n",
    "validation_data    = DataLoader(validation_data, batch_size=None, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "optimum-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (268.5665796717347, 20.29343380365656),\n",
       " 1: (264.9757803213727, 23.312992560374052),\n",
       " 2: (265.45348009405046, 13.75845443481109),\n",
       " 3: (257.0582191483074, 9.455841612721185),\n",
       " 4: (286.3129319424382, 14.495873546238812),\n",
       " 5: (22.564311828462827, 16.375402352734177),\n",
       " 6: (164.17300322756427, 452.12711641524135)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "detailed-defendant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741745, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ideal-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (268.5665796717347, 20.29343380365656), 1: (264.9757803213727, 23.312992560374052), 2: (265.45348009405046, 13.75845443481109), 3: (257.0582191483074, 9.455841612721185), 4: (286.3129319424382, 14.495873546238812), 5: (22.564311828462827, 16.375402352734177), 6: (164.17300322756427, 452.12711641524135)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(247248, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_test_jan_lpa_pr1.nc\"), \n",
    "               inputs, outputs, latlims = latlims, normalise = norm, pratio = None,\n",
    "               batch_size = batchSize, transform = None) \n",
    "validation_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "numeric-semester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qrnn_gmi_nn_lpaesa_pr1_v0_jan_v.nc\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8da8ea9a1faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                    \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                    \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                    \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                   );\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/quantnn/quantnn/qrnn.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, validation_data, batch_size, optimizer, scheduler, n_epochs, adversarial_training, device, mask, logger, metrics, keys)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mtransformation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/quantnn/quantnn/neural_network_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, loss, validation_data, optimizer, scheduler, n_epochs, adversarial_training, batch_size, device, logger, metrics, keys, transformation)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mtransformation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/quantnn/quantnn/models/pytorch/common.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, validation_data, loss, optimizer, scheduler, n_epochs, adversarial_training, batch_size, device, logger, metrics, keys, transformation)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m             raise RuntimeError(\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "for i in [\"0\"]:\n",
    "    \n",
    "    filename          = \"qrnn_gmi_nn_lpaesa_pr1_v\" + i + \"_jan_v.nc\"\n",
    "    outputfile        = os.path.join(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/try_training/\"), \n",
    "                                                        filename)\n",
    "\n",
    "    print(filename)\n",
    "    skip_connections  = True\n",
    "    batch_norm        = True\n",
    "\n",
    "    skip_connections  = True\n",
    "    batch_norm        = True\n",
    "    transform         = LogLinear()\n",
    "\n",
    "    model             = FullyConnected(ninputs,\n",
    "                           quantiles.size,\n",
    "                           n_layers,\n",
    "                           n_neurons,\n",
    "                           skip_connections=skip_connections,\n",
    "                           batch_norm=batch_norm)\n",
    "\n",
    "    #model = FullyConnected(n_inputs=ninputs, n_outputs=len(quantiles), n_layers=5, width=256)\n",
    "\n",
    "    qrnn             = QRNN(quantiles, ninputs,  model, transformation = transform)\n",
    "\n",
    "    metrics          = [\"MeanSquaredError\", \"Bias\", \"CRPS\", \"CalibrationPlot\"]\n",
    "\n",
    "    n_epochs         = 200\n",
    "    logger = TensorBoardLogger(n_epochs)\n",
    "\n",
    "    scatter_plot    = ScatterPlot(bins=np.logspace(-2, 2, 21), log_scale=True)\n",
    "    metrics.append(scatter_plot)\n",
    "\n",
    "    for lr, n_epochs in zip([1e-2, 1e-3, 1e-4], [50, 50, 100]):\n",
    "\n",
    "    #for lr, n_epochs in zip([5e-3, 1e-4, 1e-5], [20, 50, 100]):\n",
    "\n",
    "    #for lr, n_epochs in zip([0.01], [120]):\n",
    "\n",
    "        #optimizer = Adam(qrnn.model.parameters(), lr=lr)\n",
    "\n",
    "        optimizer = optim.SGD(model.parameters(), lr = lr, momentum = 0.9)\n",
    "\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
    "\n",
    "        qrnn.train(training_data=training_data,\n",
    "                   validation_data=validation_data,\n",
    "                   n_epochs=n_epochs,\n",
    "                   mask=-999,\n",
    "                   device=\"cuda\",\n",
    "                   logger=logger,\n",
    "                   metrics=metrics,\n",
    "                   optimizer=optimizer, \n",
    "                   scheduler=scheduler,\n",
    "                  );\n",
    "\n",
    "    qrnn.save(outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-victory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrnn.save(outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "y_pre = []\n",
    "y = []\n",
    "y_prior = []\n",
    "y_pos_mean = []\n",
    "x_in = []\n",
    "\n",
    "nbatch = len(validation_data)\n",
    "print (nbatch)\n",
    "for i in range(nbatch):\n",
    "    \n",
    "    xx, yy = validation_data[i]\n",
    "    \n",
    "    x = xx.detach().numpy() \n",
    "\n",
    "    y_pre.append(qrnn.predict(xx)) \n",
    "    y_pos_mean.append((qrnn.posterior_mean(xx)))\n",
    "       \n",
    "    y.append(yy.detach().numpy())\n",
    "    x_in.append(x)\n",
    "\n",
    "x_in = np.concatenate(x_in, axis = 0)\n",
    "y_pre = np.concatenate(y_pre, axis = 0)\n",
    "y = np.concatenate(y, axis= 0)\n",
    "y_pos_mean = np.concatenate(y_pos_mean, axis = 0)\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "bins1 = np.arange(0, 30, 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize = [8, 8])\n",
    "bins1 = np.arange(0, 30, 0.1)\n",
    "\n",
    "ax.hist(y_pre[:, imedian], bins1, density = True , histtype = \"step\", label = \"predicted\")\n",
    "\n",
    "\n",
    "ax.hist(y, bins1, density = True, histtype = \"step\", label = \"observed\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"PDF\")\n",
    "ax.set_xlabel(\"IWP[kg/m2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from matplotlib import ticker, cm\n",
    "xyrange = [[0, 25], [0, 25]] # data range\n",
    "\n",
    "\n",
    "bins = [50, 50] # number of bins\n",
    "hh, locx, locy = np.histogram2d(y, y_pos_mean, \n",
    "                                range=xyrange, bins=bins, density = True)\n",
    "posx = np.digitize(y, locx)\n",
    "posy = np.digitize(y_pos_mean, locy)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [10, 8])\n",
    "cs = ax.contourf(np.flipud(hh.T),\n",
    "                extent=np.array(xyrange).flatten(), \n",
    "            locator= ticker.LogLocator(), origin='upper')\n",
    "cbar = fig.colorbar(cs)\n",
    "ax.set_ylim([0, 20])\n",
    "ax.set_xlim([0, 20])\n",
    "xy = np.arange(0, 13, 1)\n",
    "yy = xy\n",
    "ax.plot(xy, yy)\n",
    "ax.set_ylabel(\"IWP Predicted [kg/m2]\")\n",
    "ax.set_xlabel(\"IWP Observed [kg/m2]\")\n",
    "ax.grid('on')\n",
    "fig.savefig(\"qrnn.png\", bbox_inches = \"tight\")\n",
    "#ax.set_yscale('log')\n",
    "#ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-charlotte",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-spare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
